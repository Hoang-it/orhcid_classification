{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sof_fast_rcnn_resnet50_fpn",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMg+0Hq8ErBP0H96+2Dy5d/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hoang-it/orhcid_classification/blob/main/sof/sof_fast_rcnn_resnet50_fpn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZa_USttGktq"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlCUsDvIHd7j"
      },
      "source": [
        "class PennFudanDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root, transforms):\n",
        "    self.root = root\n",
        "    self.transforms = transforms\n",
        "    self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\"))))\n",
        "    self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\"))))\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
        "    mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx])\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "    mask = Image.open(mask_path)\n",
        "    mask = np.array(mask)\n",
        "    obj_ids = np.unique(mask)\n",
        "    obj_ids = obj_ids[1:]\n",
        "\n",
        "    masks = mask == obj_ids[:, None, None]\n",
        "\n",
        "    num_objs = len(obj_ids)\n",
        "    boxes = []\n",
        "    for i in range(num_objs):\n",
        "      pos = np.where(masks[i])\n",
        "      xmin = np.min(pos[1])\n",
        "      xmax = np.max(pos[1])\n",
        "      ymin = np.min(pos[0])\n",
        "      ymax = np.max(pos[0])\n",
        "      boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "    labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "    masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "\n",
        "    image_id = torch.tensor([idx])\n",
        "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "    iscrowd = torch.zeross((num_objs,), dtype=torch.int64)\n",
        "\n",
        "    target = {}\n",
        "    target[\"boxes\"] = boxes\n",
        "    target[\"labels\"] = labels\n",
        "    target[\"masks\"] = masks\n",
        "    target[\"image_id\"] = image_id\n",
        "    target[\"area\"] = area\n",
        "    target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "    if self.transforms is not None:\n",
        "      img, target = self.transforms(img, target)\n",
        "    \n",
        "    return img, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}